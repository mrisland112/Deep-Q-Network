{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SP9IBnK0i7aW"
      },
      "source": [
        "#Deep Q-Network (Pong Problem)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ah9sJ36orxIG"
      },
      "source": [
        "1.Environment Preparation (OpenAI Gym)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1bLTkEs6fFx",
        "outputId": "ccda594f-a306-4091-8c24-43324fc84f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym==0.19.0 in d:\\anaconda3\\envs\\rl\\lib\\site-packages (0.19.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in d:\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.19.0) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in d:\\anaconda3\\envs\\rl\\lib\\site-packages (from gym==0.19.0) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall setuptools\n",
        "!pip install setuptools==50.3.1\n",
        "%conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0WDRListRTw",
        "outputId": "fc251109-f888-4820-e369-254b92c36ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "copying adventure.bin from ./ROM/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\adventure.bin\n",
            "copying air_raid.bin from ./ROM/Air Raid (1982) (Men-A-Vision) (PAL) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\air_raid.bin\n",
            "copying alien.bin from ./ROM/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\alien.bin\n",
            "copying amidar.bin from ./ROM/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\amidar.bin\n",
            "copying assault.bin from ./ROM/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\assault.bin\n",
            "copying asterix.bin from ./ROM/Asterix (AKA Taz) (1984) (Atari, Jerome Domurat, Steve Woita) (CX2696).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\asterix.bin\n",
            "copying asteroids.bin from ./ROM/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\asteroids.bin\n",
            "copying atlantis.bin from ./ROM/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\atlantis.bin\n",
            "copying bank_heist.bin from ./ROM/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\bank_heist.bin\n",
            "copying battle_zone.bin from ./ROM/Battlezone (1983) (Atari - GCC, Michael Feinstein, Patricia Goodson, Brad Rice) (CX2681) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\battle_zone.bin\n",
            "copying beam_rider.bin from ./ROM/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\beam_rider.bin\n",
            "copying berzerk.bin from ./ROM/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\berzerk.bin\n",
            "copying bowling.bin from ./ROM/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\bowling.bin\n",
            "copying boxing.bin from ./ROM/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\boxing.bin\n",
            "copying breakout.bin from ./ROM/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\breakout.bin\n",
            "copying carnival.bin from ./ROM/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\carnival.bin\n",
            "copying centipede.bin from ./ROM/Centipede (1983) (Atari - GCC, Patricia Goodson, Josh Littlefield, Douglas B. Macrae) (CX2676) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\centipede.bin\n",
            "copying chopper_command.bin from ./ROM/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\chopper_command.bin\n",
            "copying crazy_climber.bin from ./ROM/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\crazy_climber.bin\n",
            "copying defender.bin from ./ROM/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\defender.bin\n",
            "copying demon_attack.bin from ./ROM/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\demon_attack.bin\n",
            "copying donkey_kong.bin from ./ROM/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\donkey_kong.bin\n",
            "copying double_dunk.bin from ./ROM/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\double_dunk.bin\n",
            "copying elevator_action.bin from ./ROM/Elevator Action (1983) (Atari, Dan Hitchens, Dave Staugas) (CX26126) (Prototype) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\elevator_action.bin\n",
            "copying enduro.bin from ./ROM/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\enduro.bin\n",
            "copying fishing_derby.bin from ./ROM/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\fishing_derby.bin\n",
            "copying freeway.bin from ./ROM/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\freeway.bin\n",
            "copying frogger.bin from ./ROM/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\frogger.bin\n",
            "copying frostbite.bin from ./ROM/Frostbite (Iceman) (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\frostbite.bin\n",
            "copying galaxian.bin from ./ROM/Galaxian (1983) (Atari - GCC, Mark S. Ackerman, Tom Calderwood, Patricia Goodson, Glenn Parker) (CX2684) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\galaxian.bin\n",
            "copying gopher.bin from ./ROM/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\gopher.bin\n",
            "copying gravitar.bin from ./ROM/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\gravitar.bin\n",
            "copying hero.bin from ./ROM/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\hero.bin\n",
            "copying ice_hockey.bin from ./ROM/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\ice_hockey.bin\n",
            "copying jamesbond.bin from ./ROM/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Dan Kurczewski, Louis Marbel, Kathy Von) (PB5110) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\jamesbond.bin\n",
            "copying journey_escape.bin from ./ROM/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\journey_escape.bin\n",
            "copying kaboom.bin from ./ROM/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, CAG-010, AG-010-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\kaboom.bin\n",
            "copying kangaroo.bin from ./ROM/Kangaroo (1983) (Atari - GCC, Patricia Goodson, Josh Littlefield, Kevin Osborn) (CX2689) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\kangaroo.bin\n",
            "copying keystone_kapers.bin from ./ROM/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\keystone_kapers.bin\n",
            "copying king_kong.bin from ./ROM/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\king_kong.bin\n",
            "copying koolaid.bin from ./ROM/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\koolaid.bin\n",
            "copying krull.bin from ./ROM/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\krull.bin\n",
            "copying kung_fu_master.bin from ./ROM/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\kung_fu_master.bin\n",
            "copying laser_gates.bin from ./ROM/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\laser_gates.bin\n",
            "copying lost_luggage.bin from ./ROM/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\lost_luggage.bin\n",
            "copying montezuma_revenge.bin from ./ROM/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\montezuma_revenge.bin\n",
            "copying mr_do.bin from ./ROM/Mr. Do! (1983) (CBS Electronics - Individeo, Ed English) (4L4478) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\mr_do.bin\n",
            "copying ms_pacman.bin from ./ROM/Ms. Pac-Man (1983) (Atari - GCC, Mark S. Ackerman, Patricia Goodson, Josh Littlefield, Douglas B. Macrae, Glenn Parker) (CX2675) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\ms_pacman.bin\n",
            "copying name_this_game.bin from ./ROM/Name This Game (Guardians of Treasure, Octopussy) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\name_this_game.bin\n",
            "copying pacman.bin from ./ROM/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\pacman.bin\n",
            "copying phoenix.bin from ./ROM/Phoenix (1983) (Atari - GCC, Michael Feinstein, Patricia Goodson, John Mracek) (CX2673) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\phoenix.bin\n",
            "copying video_pinball.bin from ./ROM/Pinball (AKA Video Pinball) (Zellers).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\video_pinball.bin\n",
            "copying pitfall.bin from ./ROM/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\pitfall.bin\n",
            "copying pooyan.bin from ./ROM/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\pooyan.bin\n",
            "copying private_eye.bin from ./ROM/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\private_eye.bin\n",
            "copying qbert.bin from ./ROM/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\qbert.bin\n",
            "copying riverraid.bin from ./ROM/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\riverraid.bin\n",
            "copying road_runner.bin from patched version of ./ROM/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\road_runner.bin\n",
            "copying robotank.bin from ./ROM/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\robotank.bin\n",
            "copying seaquest.bin from ./ROM/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\seaquest.bin\n",
            "copying sir_lancelot.bin from ./ROM/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\sir_lancelot.bin\n",
            "copying skiing.bin from ./ROM/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\skiing.bin\n",
            "copying solaris.bin from ./ROM/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\solaris.bin\n",
            "copying space_invaders.bin from ./ROM/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\space_invaders.bin\n",
            "copying star_gunner.bin from ./ROM/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\star_gunner.bin\n",
            "copying surround.bin from ./ROM/Surround (32 in 1) (Bit Corporation) (R320).bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\surround.bin\n",
            "copying tennis.bin from ./ROM/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\tennis.bin\n",
            "copying time_pilot.bin from ./ROM/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\time_pilot.bin\n",
            "copying trondead.bin from ./ROM/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\trondead.bin\n",
            "copying tutankham.bin from ./ROM/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\tutankham.bin\n",
            "copying up_n_down.bin from ./ROM/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\up_n_down.bin\n",
            "copying venture.bin from ./ROM/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\venture.bin\n",
            "copying pong.bin from ./ROM/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\pong.bin\n",
            "copying wizard_of_wor.bin from ./ROM/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\wizard_of_wor.bin\n",
            "copying yars_revenge.bin from ./ROM/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\yars_revenge.bin\n",
            "copying zaxxon.bin from ./ROM/Zaxxon (1983) (Coleco) (2454) ~.bin to d:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\atari_py\\atari_roms\\zaxxon.bin\n"
          ]
        }
      ],
      "source": [
        "# 下載 ROM data 並解壓縮 (Windows)\n",
        "! wget http://www.atarimania.com/roms/Roms.rar -OutFile ./Roms.rar\n",
        "! mkdir ./ROM/\n",
        "# [使用解壓縮軟體將 rar file 解壓縮到 ./ROM/]\n",
        "! python -m atari_py.import_roms ./ROM/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gym==0.19.0                    \n",
        "# !pip install gym[atari]                     \n",
        "%conda install -c conda-forge atari_py      \n",
        "!pip install numpy\n",
        "!pip install matplotlib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "40_4Qb0wwE-B"
      },
      "source": [
        "2.Pong Game and Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "rQklMVvDwLzn",
        "outputId": "176699e5-bb2d-45c6-bb03-3861ebf747f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "environment: PongNoFrameskip-v4\n",
            "action space: 6\n",
            "action: ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n",
            "observation space: (210, 160, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x20827cfad60>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Create PongNoFrameskip-v4 environment\n",
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "env_name = \"PongNoFrameskip-v4\"\n",
        "env = gym.make(env_name)\n",
        "\n",
        "print(\"environment:\", env_name)\n",
        "print(\"action space:\", env.action_space.n)\n",
        "print(\"action:\", env.unwrapped.get_action_meanings())\n",
        "print(\"observation space:\", env.observation_space.shape)\n",
        "state = env.reset()\n",
        "action = env.action_space.sample()\n",
        "state_next, reward, done, info = env.step(action)\n",
        "plt.figure()\n",
        "plt.imshow(state_next)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YiWZirbH-bP5"
      },
      "outputs": [],
      "source": [
        "# Environment wrapper\n",
        "class PongEnvWrapper(gym.Wrapper):\n",
        "  def __init__(self, env, k, img_size=(84,84)):\n",
        "    gym.Wrapper.__init__(self, env)\n",
        "    self.k = k\n",
        "    self.img_size = img_size\n",
        "    obs_shape = env.observation_space.shape\n",
        "    self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(k, img_size[0],img_size[1]), dtype=np.float32)\n",
        "  \n",
        "  # Image preprocessing\n",
        "  def _preprocess(self, state, th=0.4):\n",
        "    state = np.array(Image.fromarray(state).resize(self.img_size, Image.BILINEAR))\n",
        "    state = state.astype(np.float64).mean(2) / 255.\n",
        "    state[state > th] = 1.0\n",
        "    state[state <= th] = 0.0\n",
        "    return state\n",
        "  \n",
        "  #Stack frames\n",
        "  def reset(self):\n",
        "    state = self.env.reset()\n",
        "    state = self._preprocess(state)\n",
        "    #Constrct initial stacked frame\n",
        "    state = state[np.newaxis, ...].repeat(self.k, axis=0)\n",
        "    return state\n",
        "\n",
        "  # Construct stacked frames\n",
        "  def step(self, action):\n",
        "    state_next = []\n",
        "    info = []\n",
        "    reward = 0\n",
        "    done = False\n",
        "    for i in range(self.k):\n",
        "      if not done:\n",
        "        state_next_f, reward_f, done_f, info_f = self.env.step(action)\n",
        "        state_next_f = self._preprocess(state_next_f)\n",
        "        reward += reward_f\n",
        "        done = done_f\n",
        "        info.append(info_f)\n",
        "      state_next.append(state_next_f[np.newaxis, ...])\n",
        "    state_next = np.concatenate(state_next, 0)\n",
        "    return state_next, reward, done, info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "urjhW_ExHBmc",
        "outputId": "ef2edd53-dbe0-4eb0-f835-44319785a77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "observation space: (4, 84, 84)\n",
            "(4, 84, 84)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x20827e62a30>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test Code\n",
        "env_pong = PongEnvWrapper(env, k=4, img_size=(84,84))\n",
        "print(\"observation space:\", env_pong.observation_space.shape)\n",
        "\n",
        "state = env_pong.reset()\n",
        "action = env_pong.action_space.sample()\n",
        "state_next, reward, done, info = env_pong.step(action)\n",
        "print(state_next.shape)\n",
        "plt.imshow(state_next[0], cmap=\"gray\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz-YhM62NBvB"
      },
      "source": [
        "3.Reinforcement Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d-rNxyBeNBLZ"
      },
      "outputs": [],
      "source": [
        "# CNN\n",
        "class QNet(nn.Module):\n",
        "  def __init__(self, input_shape, n_actions):\n",
        "    super(QNet, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "      nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "      nn.ReLU(), \n",
        "      nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "      nn.ReLU(), \n",
        "    )\n",
        "\n",
        "    conv_out_size = self._get_conv_out(input_shape)\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(conv_out_size, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, n_actions),\n",
        "    )\n",
        "\n",
        "  def _get_conv_out(self,shape):\n",
        "    o = self.conv(torch.zeros(1, *shape))\n",
        "    return int(np.prod(o.size()))\n",
        "\n",
        "  def forward(self, x):\n",
        "    conv_out = self.conv(x)\n",
        "    out = self.fc(conv_out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fFo3xqqgSbGt"
      },
      "outputs": [],
      "source": [
        "# Build DQN\n",
        "class DeepQNetwork():\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_actions,\n",
        "        input_shape,\n",
        "        qnet,\n",
        "        device,\n",
        "        learning_rate = 2e-4,\n",
        "        reward_decay = 0.99,\n",
        "        replace_target_iter = 1000,\n",
        "        memory_size = 10000,\n",
        "        batch_size = 32,\n",
        "    ):\n",
        "        # initialize parameters\n",
        "        self.n_actions = n_actions\n",
        "        self.input_shape = input_shape\n",
        "        self.lr = learning_rate\n",
        "        self.gamma = reward_decay\n",
        "        self.replace_target_iter = replace_target_iter\n",
        "        self.memory_size = memory_size\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.learn_step_counter = 0\n",
        "        self.init_memory()\n",
        "\n",
        "        # Network\n",
        "        self.qnet_eval = qnet(self.input_shape, self.n_actions).to(self.device)\n",
        "        self.qnet_target = qnet(self.input_shape, self.n_actions).to(self.device)\n",
        "        self.qnet_target.eval()\n",
        "        self.optimizer = optim.RMSprop(self.qnet_eval.parameters(), lr=self.lr)\n",
        "\n",
        "    def choose_action(self, state, epsilon=0):\n",
        "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
        "        actions_value = self.qnet_eval.forward(state)\n",
        "        if np.random.uniform() > epsilon:   # epsilon-greedy\n",
        "            action = torch.max(actions_value, 1)[1].data.cpu().numpy()[0]\n",
        "        else:   # random\n",
        "            action = np.random.randint(0, self.n_actions)\n",
        "        return action\n",
        "\n",
        "    def learn(self):\n",
        "        # check to replace target parameters\n",
        "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
        "            self.qnet_target.load_state_dict(self.qnet_eval.state_dict())\n",
        "\n",
        "        # sample batch memory from all memory\n",
        "        if self.memory_counter > self.memory_size:\n",
        "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
        "        else:\n",
        "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
        "\n",
        "        b_s = torch.FloatTensor(self.memory[\"s\"][sample_index]).to(self.device)\n",
        "        b_a = torch.LongTensor(self.memory[\"a\"][sample_index]).to(self.device)\n",
        "        b_r = torch.FloatTensor(self.memory[\"r\"][sample_index]).to(self.device)\n",
        "        b_s_ = torch.FloatTensor(self.memory[\"s_\"][sample_index]).to(self.device)\n",
        "        b_d = torch.FloatTensor(self.memory[\"done\"][sample_index]).to(self.device)\n",
        "\n",
        "        q_curr_eval = self.qnet_eval(b_s).gather(1, b_a)\n",
        "        q_next_target = self.qnet_target(b_s_).detach()\n",
        "\n",
        "        next_state_values = q_next_target.max(1)[0].view(-1, 1)   # DQN\n",
        "\n",
        "        q_curr_recur = b_r + (1-b_d) * self.gamma * next_state_values\n",
        "        self.loss = F.smooth_l1_loss(q_curr_eval, q_curr_recur)\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        self.loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.learn_step_counter += 1\n",
        "        return self.loss.detach().cpu().numpy()\n",
        "\n",
        "    def init_memory(self):\n",
        "        self.memory = {\n",
        "            \"s\": np.zeros((self.memory_size, *self.input_shape)),\n",
        "            \"a\": np.zeros((self.memory_size, 1)),\n",
        "            \"r\": np.zeros((self.memory_size, 1)),\n",
        "            \"s_\": np.zeros((self.memory_size, *self.input_shape)),\n",
        "            \"done\": np.zeros((self.memory_size, 1)),\n",
        "        }\n",
        "\n",
        "    def store_transition(self, s, a, r, s_, d):\n",
        "        if not hasattr(self, 'memory_counter'):\n",
        "            self.memory_counter = 0\n",
        "        if self.memory_counter <= self.memory_size:\n",
        "            index = self.memory_counter % self.memory_size\n",
        "        else:\n",
        "            index = np.random.randint(self.memory_size)\n",
        "        self.memory[\"s\"][index] = s\n",
        "        self.memory[\"a\"][index] = np.array(a).reshape(-1,1)\n",
        "        self.memory[\"r\"][index] = np.array(r).reshape(-1,1)\n",
        "        self.memory[\"s_\"][index] = s_\n",
        "        self.memory[\"done\"][index] = np.array(d).reshape(-1,1)\n",
        "        self.memory_counter += 1\n",
        "    \n",
        "    def save_load_model(self, op, path=\"save\", fname=\"qnet.pt\"):\n",
        "        import os\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        file_path = os.path.join(path, fname)\n",
        "        if op == \"save\":\n",
        "            torch.save(self.qnet_eval.state_dict(), file_path)\n",
        "        elif op == \"load\":\n",
        "            self.qnet_eval.load_state_dict(torch.load(file_path, map_location=self.device))\n",
        "            self.qnet_target.load_state_dict(torch.load(file_path, map_location=self.device))\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaKs84Jfap0K",
        "outputId": "d52c206a-043e-44d3-ea41-b6ee06addd64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QNet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "stack_frames = 4\n",
        "img_size = (84,84)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "agent = DeepQNetwork(\n",
        "        n_actions = env.action_space.n,\n",
        "        input_shape = [stack_frames, *img_size],\n",
        "        qnet = QNet,\n",
        "        device = device,\n",
        "        learning_rate = 2e-4, \n",
        "        reward_decay = 0.99,\n",
        "        replace_target_iter = 1000, \n",
        "        memory_size = 10000,\n",
        "        batch_size = 32,)\n",
        "\n",
        "print(agent.qnet_eval)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xVXyFwoccfj4"
      },
      "source": [
        "4.Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OCceDANycYAM"
      },
      "outputs": [],
      "source": [
        "def play(env, agent, stack_frames, img_size):\n",
        "    # Reset environment.\n",
        "    state = env.reset()\n",
        "    img_buffer = [Image.fromarray(state[0]*255)]\n",
        "\n",
        "    # Initialize information.\n",
        "    step = 0\n",
        "    total_reward = 0\n",
        "\n",
        "    # One episode.\n",
        "    while True:\n",
        "        # Select action.\n",
        "        action = agent.choose_action(state, 0)\n",
        "\n",
        "        # Get next stacked state.\n",
        "        state_next, reward, done, info = env.step(action)\n",
        "        if step % 2 == 0:\n",
        "            img_buffer.append(Image.fromarray(state_next[0]*255))\n",
        "\n",
        "        state = state_next.copy()\n",
        "        step += 1\n",
        "        total_reward += reward\n",
        "        print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f}'\\\n",
        "            .format(step, reward, total_reward), end=\"\")\n",
        "            \n",
        "        if done or step>2000:\n",
        "            print()\n",
        "            break\n",
        "\n",
        "    return img_buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BmWvmTUbcjr9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def save_gif(img_buffer, fname, gif_path=os.path.join(\"/content/\", \"gif\")):\n",
        "    if not os.path.exists(gif_path):\n",
        "        os.makedirs(gif_path)\n",
        "    img_buffer[0].save(os.path.join(gif_path, fname), save_all=True, append_images=img_buffer[1:], duration=1, loop=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1yj8Wdwc16J",
        "outputId": "34b0e8dd-1834-4d4b-d2f0-18be3189e2c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 764 | Reward: -1.000 / -21.000\n"
          ]
        }
      ],
      "source": [
        "# Test Code\n",
        "img_buffer = play(env_pong, agent, stack_frames, img_size)\n",
        "save_gif(img_buffer, fname=\"test.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0n5S6i4kduJ0"
      },
      "outputs": [],
      "source": [
        "#epsilon-greedy compute\n",
        "def epsilon_compute(frame_id, epsilon_max=1, epsilon_min=0.05, epsilon_decay=100000):\n",
        "    return epsilon_min + (epsilon_max - epsilon_min) * np.exp(-frame_id / epsilon_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "iN1A4p7UdxTh",
        "outputId": "595019f6-559e-4c5c-ccd2-fdb723ea4d65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x20802fe35b0>]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test Code\n",
        "frame_ids = np.array(range(400000))\n",
        "epsilons = epsilon_compute(frame_ids)\n",
        "plt.plot(epsilons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "F56PZCWwd1xS"
      },
      "outputs": [],
      "source": [
        "# Start Training\n",
        "def train(env, agent, stack_frames, img_size, save_path=\"save\", max_steps=1000000):\n",
        "    total_step = 0\n",
        "    episode = 0\n",
        "    while True:\n",
        "        # Reset environment.\n",
        "        state = env.reset()\n",
        "\n",
        "        # Initialize information.\n",
        "        step = 0\n",
        "        total_reward = 0\n",
        "        loss = 0\n",
        "\n",
        "        # One episode.\n",
        "        while True:\n",
        "            # Select action.\n",
        "            epsilon = epsilon_compute(total_step)\n",
        "            action = agent.choose_action(state, epsilon)\n",
        "\n",
        "            # Get next stacked state.\n",
        "            state_next, reward, done, info = env.step(action)\n",
        "\n",
        "            # Store transition and learn.\n",
        "            agent.store_transition(state, action, reward, state_next, done)\n",
        "            if total_step > 4*agent.batch_size:\n",
        "                loss = agent.learn()\n",
        "\n",
        "            state = state_next.copy()\n",
        "            step += 1\n",
        "            total_step += 1\n",
        "            total_reward += reward\n",
        "\n",
        "            if total_step % 100 == 0 or done:\n",
        "                print('\\rEpisode: {:3d} | Step: {:3d} / {:3d} | Reward: {:.3f} / {:.3f} | Loss: {:.3f} | Epsilon: {:.3f}'\\\n",
        "                    .format(episode, step, total_step, reward, total_reward, loss, epsilon), end=\"\")\n",
        "            \n",
        "            if total_step % 10000 == 0:\n",
        "                print(\"\\nSave Model ...\")\n",
        "                agent.save_load_model(op=\"save\", path=save_path, fname=\"qnet.pt\")\n",
        "                print(\"Generate GIF ...\")\n",
        "                img_buffer = play(env, agent, stack_frames, img_size)\n",
        "                save_gif(img_buffer, \"train_\" + str(total_step).zfill(6) + \".gif\")\n",
        "                print(\"Done !!\")\n",
        "\n",
        "            if done or step>2000:\n",
        "                episode += 1\n",
        "                print()\n",
        "                break\n",
        "        \n",
        "        if total_step > max_steps:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKt0-9LmeCTl",
        "outputId": "046c3ad7-db45-4ea8-f8d5-8c1e2f9ff2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode:   0 | Step: 1013 / 1013 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.990\n",
            "Episode:   1 | Step: 842 / 1855 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.983\n",
            "Episode:   2 | Step: 976 / 2831 | Reward: -1.000 / -20.000 | Loss: 0.015 | Epsilon: 0.973\n",
            "Episode:   3 | Step: 850 / 3681 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.966\n",
            "Episode:   4 | Step: 944 / 4625 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.957\n",
            "Episode:   5 | Step: 902 / 5527 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.949\n",
            "Episode:   6 | Step: 824 / 6351 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.942\n",
            "Episode:   7 | Step: 792 / 7143 | Reward: -1.000 / -21.000 | Loss: 0.002 | Epsilon: 0.935\n",
            "Episode:   8 | Step: 838 / 7981 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.927\n",
            "Episode:   9 | Step: 931 / 8912 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.919\n",
            "Episode:  10 | Step: 849 / 9761 | Reward: -1.000 / -21.000 | Loss: 0.003 | Epsilon: 0.912\n",
            "Episode:  11 | Step: 239 / 10000 | Reward: -1.000 / -6.000 | Loss: 0.002 | Epsilon: 0.910\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 764 | Reward: -1.000 / -21.000\n",
            "Done !!\n",
            "Episode:  11 | Step: 240 / 10001 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.910\n",
            "Episode:  12 | Step: 979 / 10980 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.901\n",
            "Episode:  13 | Step: 882 / 11862 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.894\n",
            "Episode:  14 | Step: 1052 / 12914 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.885\n",
            "Episode:  15 | Step: 1096 / 14010 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.876\n",
            "Episode:  16 | Step: 1078 / 15088 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.867\n",
            "Episode:  17 | Step: 1052 / 16140 | Reward: -1.000 / -21.000 | Loss: 0.004 | Epsilon: 0.858\n",
            "Episode:  18 | Step: 953 / 17093 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.851\n",
            "Episode:  19 | Step: 987 / 18080 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.843\n",
            "Episode:  20 | Step: 1012 / 19092 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.835\n",
            "Episode:  21 | Step: 908 / 20000 | Reward: 0.000 / -19.000 | Loss: 0.002 | Epsilon: 0.828\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -13.0000\n",
            "Done !!\n",
            "Episode:  21 | Step: 973 / 20065 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.827\n",
            "Episode:  22 | Step: 1064 / 21129 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.819\n",
            "Episode:  23 | Step: 1009 / 22138 | Reward: -1.000 / -20.000 | Loss: 0.004 | Epsilon: 0.811\n",
            "Episode:  24 | Step: 1264 / 23402 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.802\n",
            "Episode:  25 | Step: 1194 / 24596 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.793\n",
            "Episode:  26 | Step: 968 / 25564 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.786\n",
            "Episode:  27 | Step: 1117 / 26681 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.778\n",
            "Episode:  28 | Step: 1622 / 28303 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.766\n",
            "Episode:  29 | Step: 1068 / 29371 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.758\n",
            "Episode:  30 | Step: 629 / 30000 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.754\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 1997 | Reward: -1.000 / -18.000\n",
            "Done !!\n",
            "Episode:  30 | Step: 630 / 30001 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.754\n",
            "Episode:  31 | Step: 1192 / 31193 | Reward: -1.000 / -21.000 | Loss: 0.002 | Epsilon: 0.745\n",
            "Episode:  32 | Step: 1013 / 32206 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.738\n",
            "Episode:  33 | Step: 1329 / 33535 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.729\n",
            "Episode:  34 | Step: 1314 / 34849 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.720\n",
            "Episode:  35 | Step: 1078 / 35927 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.713\n",
            "Episode:  36 | Step: 1110 / 37037 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.706\n",
            "Episode:  37 | Step: 1157 / 38194 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.698\n",
            "Episode:  38 | Step: 986 / 39180 | Reward: -1.000 / -20.000 | Loss: 0.003 | Epsilon: 0.692\n",
            "Episode:  39 | Step: 820 / 40000 | Reward: 0.000 / -15.000 | Loss: 0.001 | Epsilon: 0.687\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -15.0000\n",
            "Done !!\n",
            "Episode:  39 | Step: 944 / 40124 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.686\n",
            "Episode:  40 | Step: 1034 / 41158 | Reward: -1.000 / -21.000 | Loss: 0.003 | Epsilon: 0.679\n",
            "Episode:  41 | Step: 1321 / 42479 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.671\n",
            "Episode:  42 | Step: 1397 / 43876 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.663\n",
            "Episode:  43 | Step: 1167 / 45043 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.655\n",
            "Episode:  44 | Step: 1383 / 46426 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.647\n",
            "Episode:  45 | Step: 1279 / 47705 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.640\n",
            "Episode:  46 | Step: 1327 / 49032 | Reward: -1.000 / -20.000 | Loss: 0.000 | Epsilon: 0.632\n",
            "Episode:  47 | Step: 968 / 50000 | Reward: 0.000 / -13.000 | Loss: 0.001 | Epsilon: 0.626\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -9.0000\n",
            "Done !!\n",
            "Episode:  47 | Step: 1116 / 50148 | Reward: -1.000 / -18.000 | Loss: 0.002 | Epsilon: 0.625\n",
            "Episode:  48 | Step: 1121 / 51269 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.619\n",
            "Episode:  49 | Step: 1083 / 52352 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.613\n",
            "Episode:  50 | Step: 1387 / 53739 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.605\n",
            "Episode:  51 | Step: 1214 / 54953 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.598\n",
            "Episode:  52 | Step: 1227 / 56180 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.592\n",
            "Episode:  53 | Step: 1243 / 57423 | Reward: -1.000 / -21.000 | Loss: 0.001 | Epsilon: 0.585\n",
            "Episode:  54 | Step: 1615 / 59038 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.576\n",
            "Episode:  55 | Step: 962 / 60000 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.571\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -14.0000\n",
            "Done !!\n",
            "Episode:  55 | Step: 1116 / 60154 | Reward: -1.000 / -12.000 | Loss: 0.002 | Epsilon: 0.571\n",
            "Episode:  56 | Step: 1512 / 61666 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.563\n",
            "Episode:  57 | Step: 1146 / 62812 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.557\n",
            "Episode:  58 | Step: 1234 / 64046 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.551\n",
            "Episode:  59 | Step: 1502 / 65548 | Reward: -1.000 / -14.000 | Loss: 0.002 | Epsilon: 0.543\n",
            "Episode:  60 | Step: 1373 / 66921 | Reward: -1.000 / -17.000 | Loss: 0.000 | Epsilon: 0.537\n",
            "Episode:  61 | Step: 1459 / 68380 | Reward: -1.000 / -17.000 | Loss: 0.003 | Epsilon: 0.529\n",
            "Episode:  62 | Step: 1322 / 69702 | Reward: -1.000 / -18.000 | Loss: 0.002 | Epsilon: 0.523\n",
            "Episode:  63 | Step: 298 / 70000 | Reward: 0.000 / -2.000 | Loss: 0.001 | Epsilon: 0.522\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -15.0000\n",
            "Done !!\n",
            "Episode:  63 | Step: 396 / 70098 | Reward: -1.000 / -5.000 | Loss: 0.001 | Epsilon: 0.521\n",
            "Episode:  64 | Step: 1461 / 71559 | Reward: -1.000 / -18.000 | Loss: 0.002 | Epsilon: 0.514\n",
            "Episode:  65 | Step: 1431 / 72990 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.508\n",
            "Episode:  66 | Step: 1894 / 74884 | Reward: -1.000 / -16.000 | Loss: 0.003 | Epsilon: 0.499\n",
            "Episode:  67 | Step: 1226 / 76110 | Reward: -1.000 / -20.000 | Loss: 0.003 | Epsilon: 0.494\n",
            "Episode:  68 | Step: 1141 / 77251 | Reward: -1.000 / -20.000 | Loss: 0.002 | Epsilon: 0.489\n",
            "Episode:  69 | Step: 1836 / 79087 | Reward: -1.000 / -15.000 | Loss: 0.001 | Epsilon: 0.481\n",
            "Episode:  70 | Step: 913 / 80000 | Reward: 0.000 / -12.000 | Loss: 0.002 | Epsilon: 0.477\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -10.0000\n",
            "Done !!\n",
            "Episode:  70 | Step: 1348 / 80435 | Reward: -1.000 / -14.000 | Loss: 0.002 | Epsilon: 0.475\n",
            "Episode:  71 | Step: 1620 / 82055 | Reward: -1.000 / -17.000 | Loss: 0.008 | Epsilon: 0.468\n",
            "Episode:  72 | Step: 1729 / 83784 | Reward: -1.000 / -18.000 | Loss: 0.002 | Epsilon: 0.461\n",
            "Episode:  73 | Step: 1247 / 85031 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.456\n",
            "Episode:  74 | Step: 1969 / 87000 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.448\n",
            "Episode:  75 | Step: 1759 / 88791 | Reward: -1.000 / -20.000 | Loss: 0.001 | Epsilon: 0.441\n",
            "Episode:  76 | Step: 1209 / 90000 | Reward: 0.000 / -8.000 | Loss: 0.001 | Epsilon: 0.4367\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -8.0000\n",
            "Done !!\n",
            "Episode:  76 | Step: 1909 / 90700 | Reward: 0.000 / -15.000 | Loss: 0.001 | Epsilon: 0.434\n",
            "Episode:  77 | Step: 1276 / 92068 | Reward: -1.000 / -19.000 | Loss: 0.006 | Epsilon: 0.428\n",
            "Episode:  78 | Step: 1932 / 94000 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.421\n",
            "Episode:  79 | Step: 1873 / 95942 | Reward: -1.000 / -17.000 | Loss: 0.002 | Epsilon: 0.414\n",
            "Episode:  80 | Step: 1899 / 97841 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.407\n",
            "Episode:  81 | Step: 1959 / 99800 | Reward: -1.000 / -19.000 | Loss: 0.002 | Epsilon: 0.400\n",
            "Episode:  82 | Step: 200 / 100000 | Reward: 0.000 / -2.000 | Loss: 0.001 | Epsilon: 0.399\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -9.0000\n",
            "Done !!\n",
            "Episode:  82 | Step: 761 / 100561 | Reward: -1.000 / -9.000 | Loss: 0.001 | Epsilon: 0.398\n",
            "Episode:  83 | Step: 1695 / 102256 | Reward: -1.000 / -15.000 | Loss: 0.001 | Epsilon: 0.392\n",
            "Episode:  84 | Step: 1676 / 103932 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.386\n",
            "Episode:  85 | Step: 1968 / 105900 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.379\n",
            "Episode:  86 | Step: 1716 / 107649 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.374\n",
            "Episode:  87 | Step: 1951 / 109600 | Reward: 0.000 / -11.000 | Loss: 0.000 | Epsilon: 0.367\n",
            "Episode:  88 | Step: 350 / 110000 | Reward: 0.000 / 0.000 | Loss: 0.001 | Epsilon: 0.3667\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -3.0000\n",
            "Done !!\n",
            "Episode:  88 | Step: 1426 / 111076 | Reward: -1.000 / -8.000 | Loss: 0.004 | Epsilon: 0.363\n",
            "Episode:  89 | Step: 1924 / 113000 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.357\n",
            "Episode:  90 | Step: 1923 / 115000 | Reward: 0.000 / -9.000 | Loss: 0.000 | Epsilon: 0.3511\n",
            "Episode:  91 | Step: 1922 / 117000 | Reward: 0.000 / -13.000 | Loss: 0.001 | Epsilon: 0.3456\n",
            "Episode:  92 | Step: 1755 / 118834 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.339\n",
            "Episode:  93 | Step: 1166 / 120000 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.336\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -5.0000\n",
            "Done !!\n",
            "Episode:  93 | Step: 1940 / 120774 | Reward: -1.000 / -16.000 | Loss: 0.001 | Epsilon: 0.334\n",
            "Episode:  94 | Step: 1888 / 122662 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.329\n",
            "Episode:  95 | Step: 1901 / 124563 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.323\n",
            "Episode:  96 | Step: 1937 / 126500 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.318\n",
            "Episode:  97 | Step: 1996 / 128560 | Reward: -1.000 / -14.000 | Loss: 0.002 | Epsilon: 0.313\n",
            "Episode:  98 | Step: 1440 / 130000 | Reward: 0.000 / -18.000 | Loss: 0.002 | Epsilon: 0.309\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -17.0000\n",
            "Done !!\n",
            "Episode:  98 | Step: 1517 / 130077 | Reward: -1.000 / -19.000 | Loss: 0.001 | Epsilon: 0.309\n",
            "Episode:  99 | Step: 1791 / 131868 | Reward: -1.000 / -17.000 | Loss: 0.001 | Epsilon: 0.304\n",
            "Episode: 100 | Step: 1729 / 133597 | Reward: -1.000 / -14.000 | Loss: 0.001 | Epsilon: 0.300\n",
            "Episode: 101 | Step: 1903 / 135500 | Reward: 0.000 / -13.000 | Loss: 0.002 | Epsilon: 0.295\n",
            "Episode: 102 | Step: 1701 / 137299 | Reward: -1.000 / -19.000 | Loss: 0.003 | Epsilon: 0.291\n",
            "Episode: 103 | Step: 2001 / 139300 | Reward: 0.000 / -7.000 | Loss: 0.001 | Epsilon: 0.286\n",
            "Episode: 104 | Step: 700 / 140000 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.284\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -7.0000\n",
            "Done !!\n",
            "Episode: 104 | Step: 1704 / 141004 | Reward: -1.000 / -12.000 | Loss: 0.003 | Epsilon: 0.282\n",
            "Episode: 105 | Step: 1344 / 142348 | Reward: -1.000 / -20.000 | Loss: 0.019 | Epsilon: 0.279\n",
            "Episode: 106 | Step: 1952 / 144300 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.274\n",
            "Episode: 107 | Step: 1951 / 146300 | Reward: 0.000 / -10.000 | Loss: 0.002 | Epsilon: 0.270\n",
            "Episode: 108 | Step: 1720 / 148070 | Reward: -1.000 / -19.000 | Loss: 0.000 | Epsilon: 0.266\n",
            "Episode: 109 | Step: 1712 / 149782 | Reward: -1.000 / -18.000 | Loss: 0.001 | Epsilon: 0.262\n",
            "Episode: 110 | Step: 218 / 150000 | Reward: 0.000 / -1.000 | Loss: 0.002 | Epsilon: 0.262\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -7.0000\n",
            "Done !!\n",
            "Episode: 110 | Step: 1033 / 150815 | Reward: -1.000 / -5.000 | Loss: 0.001 | Epsilon: 0.260\n",
            "Episode: 111 | Step: 1985 / 152800 | Reward: 0.000 / -11.000 | Loss: 0.000 | Epsilon: 0.256\n",
            "Episode: 112 | Step: 1984 / 154800 | Reward: 0.000 / -14.000 | Loss: 0.001 | Epsilon: 0.252\n",
            "Episode: 113 | Step: 1983 / 156800 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.248\n",
            "Episode: 114 | Step: 1982 / 158800 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.244\n",
            "Episode: 115 | Step: 1181 / 160000 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.242\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -8.0000\n",
            "Done !!\n",
            "Episode: 115 | Step: 1998 / 160817 | Reward: -1.000 / -4.000 | Loss: 0.003 | Epsilon: 0.240\n",
            "Episode: 116 | Step: 1983 / 162800 | Reward: 0.000 / -12.000 | Loss: 0.001 | Epsilon: 0.237\n",
            "Episode: 117 | Step: 1982 / 164800 | Reward: 0.000 / -8.000 | Loss: 0.001 | Epsilon: 0.233\n",
            "Episode: 118 | Step: 1981 / 166800 | Reward: 0.000 / -16.000 | Loss: 0.000 | Epsilon: 0.229\n",
            "Episode: 119 | Step: 1980 / 168800 | Reward: 0.000 / -11.000 | Loss: 0.001 | Epsilon: 0.226\n",
            "Episode: 120 | Step: 1179 / 170000 | Reward: 0.000 / -9.000 | Loss: 0.000 | Epsilon: 0.224\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -4.0000\n",
            "Done !!\n",
            "Episode: 120 | Step: 1979 / 170800 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.222\n",
            "Episode: 121 | Step: 1978 / 172800 | Reward: 0.000 / -15.000 | Loss: 0.000 | Epsilon: 0.219\n",
            "Episode: 122 | Step: 1977 / 174800 | Reward: 0.000 / -12.000 | Loss: 0.000 | Epsilon: 0.215\n",
            "Episode: 123 | Step: 1976 / 176800 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.212\n",
            "Episode: 124 | Step: 1975 / 178800 | Reward: 0.000 / -7.000 | Loss: 0.000 | Epsilon: 0.209\n",
            "Episode: 125 | Step: 1174 / 180000 | Reward: 0.000 / -1.000 | Loss: 0.000 | Epsilon: 0.207\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 2.0000\n",
            "Done !!\n",
            "Episode: 125 | Step: 1974 / 180800 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.206\n",
            "Episode: 126 | Step: 1973 / 182800 | Reward: 0.000 / -16.000 | Loss: 0.001 | Epsilon: 0.203\n",
            "Episode: 127 | Step: 1972 / 184800 | Reward: 0.000 / -1.000 | Loss: 0.001 | Epsilon: 0.200\n",
            "Episode: 128 | Step: 1971 / 186800 | Reward: 0.000 / -10.000 | Loss: 0.001 | Epsilon: 0.197\n",
            "Episode: 129 | Step: 1970 / 188800 | Reward: 0.000 / -9.000 | Loss: 0.000 | Epsilon: 0.1944\n",
            "Episode: 130 | Step: 1169 / 190000 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.192\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / -1.0000\n",
            "Done !!\n",
            "Episode: 130 | Step: 1969 / 190800 | Reward: 0.000 / -10.000 | Loss: 0.000 | Epsilon: 0.1911\n",
            "Episode: 131 | Step: 1968 / 192800 | Reward: 0.000 / -12.000 | Loss: 0.000 | Epsilon: 0.1889\n",
            "Episode: 132 | Step: 1967 / 194800 | Reward: 0.000 / -2.000 | Loss: 0.000 | Epsilon: 0.185\n",
            "Episode: 133 | Step: 1966 / 196800 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.183\n",
            "Episode: 134 | Step: 1965 / 198800 | Reward: 0.000 / -5.000 | Loss: 0.000 | Epsilon: 0.180\n",
            "Episode: 135 | Step: 1164 / 200000 | Reward: 0.000 / -2.000 | Loss: 0.001 | Epsilon: 0.179\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 0.00000\n",
            "Done !!\n",
            "Episode: 135 | Step: 1964 / 200800 | Reward: 0.000 / 1.000 | Loss: 0.001 | Epsilon: 0.1788\n",
            "Episode: 136 | Step: 1963 / 202800 | Reward: 0.000 / -6.000 | Loss: 0.000 | Epsilon: 0.175\n",
            "Episode: 137 | Step: 1962 / 204800 | Reward: 0.000 / -6.000 | Loss: 0.000 | Epsilon: 0.173\n",
            "Episode: 138 | Step: 1961 / 206800 | Reward: 0.000 / -3.000 | Loss: 0.002 | Epsilon: 0.170\n",
            "Episode: 139 | Step: 1960 / 208800 | Reward: 0.000 / -5.000 | Loss: 0.001 | Epsilon: 0.168\n",
            "Episode: 140 | Step: 1159 / 210000 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.166\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 1.00000\n",
            "Done !!\n",
            "Episode: 140 | Step: 1959 / 210800 | Reward: 0.000 / -6.000 | Loss: 0.000 | Epsilon: 0.165\n",
            "Episode: 141 | Step: 1958 / 212800 | Reward: 0.000 / 2.000 | Loss: 0.001 | Epsilon: 0.1634\n",
            "Episode: 142 | Step: 1957 / 214800 | Reward: 0.000 / 0.000 | Loss: 0.001 | Epsilon: 0.1611\n",
            "Episode: 143 | Step: 1956 / 216800 | Reward: 0.000 / -1.000 | Loss: 0.001 | Epsilon: 0.159\n",
            "Episode: 144 | Step: 1955 / 218800 | Reward: 0.000 / 2.000 | Loss: 0.000 | Epsilon: 0.157\n",
            "Episode: 145 | Step: 1154 / 220000 | Reward: 0.000 / -1.000 | Loss: 0.000 | Epsilon: 0.155\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 6.0000\n",
            "Done !!\n",
            "Episode: 145 | Step: 1954 / 220800 | Reward: 0.000 / -4.000 | Loss: 0.001 | Epsilon: 0.154\n",
            "Episode: 146 | Step: 1953 / 222800 | Reward: 0.000 / -7.000 | Loss: 0.001 | Epsilon: 0.152\n",
            "Episode: 147 | Step: 1952 / 224800 | Reward: 0.000 / -5.000 | Loss: 0.000 | Epsilon: 0.150\n",
            "Episode: 148 | Step: 1951 / 226800 | Reward: 0.000 / -2.000 | Loss: 0.000 | Epsilon: 0.148\n",
            "Episode: 149 | Step: 1950 / 228800 | Reward: 0.000 / -6.000 | Loss: 0.001 | Epsilon: 0.146\n",
            "Episode: 150 | Step: 1149 / 230000 | Reward: 0.000 / 3.000 | Loss: 0.001 | Epsilon: 0.145\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 5.0000\n",
            "Done !!\n",
            "Episode: 150 | Step: 1949 / 230800 | Reward: 0.000 / -1.000 | Loss: 0.001 | Epsilon: 0.144\n",
            "Episode: 151 | Step: 1948 / 232800 | Reward: 0.000 / 8.000 | Loss: 0.002 | Epsilon: 0.143\n",
            "Episode: 152 | Step: 1947 / 234800 | Reward: 0.000 / 5.000 | Loss: 0.000 | Epsilon: 0.141\n",
            "Episode: 153 | Step: 1946 / 236800 | Reward: 0.000 / -1.000 | Loss: 0.001 | Epsilon: 0.139\n",
            "Episode: 154 | Step: 1945 / 238800 | Reward: 0.000 / 13.000 | Loss: 0.000 | Epsilon: 0.137\n",
            "Episode: 155 | Step: 1144 / 240000 | Reward: 0.000 / 0.000 | Loss: 0.001 | Epsilon: 0.136\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 16.000\n",
            "Done !!\n",
            "Episode: 155 | Step: 1237 / 240093 | Reward: 1.000 / 2.000 | Loss: 0.001 | Epsilon: 0.136\n",
            "Episode: 156 | Step: 1907 / 242000 | Reward: 0.000 / 7.000 | Loss: 0.000 | Epsilon: 0.134\n",
            "Episode: 157 | Step: 1906 / 244000 | Reward: 0.000 / 2.000 | Loss: 0.001 | Epsilon: 0.133\n",
            "Episode: 158 | Step: 1905 / 246000 | Reward: 0.000 / -3.000 | Loss: 0.001 | Epsilon: 0.131\n",
            "Episode: 159 | Step: 1904 / 248000 | Reward: 0.000 / 9.000 | Loss: 0.000 | Epsilon: 0.130\n",
            "Episode: 160 | Step: 1903 / 250000 | Reward: 0.000 / 8.000 | Loss: 0.000 | Epsilon: 0.1288\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 18.0000\n",
            "Done !!\n",
            "Episode: 160 | Step: 1949 / 250046 | Reward: 1.000 / 8.000 | Loss: 0.000 | Epsilon: 0.128\n",
            "Episode: 161 | Step: 1954 / 252000 | Reward: 0.000 / 9.000 | Loss: 0.001 | Epsilon: 0.1267\n",
            "Episode: 162 | Step: 1953 / 254000 | Reward: 0.000 / 7.000 | Loss: 0.000 | Epsilon: 0.125\n",
            "Episode: 163 | Step: 1952 / 256000 | Reward: 0.000 / 8.000 | Loss: 0.000 | Epsilon: 0.123\n",
            "Episode: 164 | Step: 1951 / 258000 | Reward: 0.000 / 16.000 | Loss: 0.000 | Epsilon: 0.122\n",
            "Episode: 165 | Step: 1950 / 260000 | Reward: 0.000 / 9.000 | Loss: 0.001 | Epsilon: 0.121\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 1878 | Reward: 1.000 / 19.0000\n",
            "Done !!\n",
            "Episode: 165 | Step: 1951 / 260001 | Reward: 0.000 / 9.000 | Loss: 0.001 | Epsilon: 0.121\n",
            "Episode: 166 | Step: 1999 / 262000 | Reward: 0.000 / 1.000 | Loss: 0.000 | Epsilon: 0.1199\n",
            "Episode: 167 | Step: 1998 / 264000 | Reward: 0.000 / 14.000 | Loss: 0.001 | Epsilon: 0.118\n",
            "Episode: 168 | Step: 1997 / 266000 | Reward: 0.000 / 12.000 | Loss: 0.001 | Epsilon: 0.116\n",
            "Episode: 169 | Step: 1996 / 268000 | Reward: 0.000 / 8.000 | Loss: 0.000 | Epsilon: 0.115\n",
            "Episode: 170 | Step: 1995 / 270000 | Reward: 0.000 / 8.000 | Loss: 0.000 | Epsilon: 0.1144\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 2001 | Reward: 0.000 / 16.0000\n",
            "Done !!\n",
            "\n",
            "Episode: 171 | Step: 1994 / 272000 | Reward: 0.000 / 9.000 | Loss: 0.001 | Epsilon: 0.1133\n",
            "Episode: 172 | Step: 1993 / 274000 | Reward: 0.000 / 14.000 | Loss: 0.000 | Epsilon: 0.111\n",
            "Episode: 173 | Step: 1992 / 276000 | Reward: 0.000 / 3.000 | Loss: 0.004 | Epsilon: 0.110\n",
            "Episode: 174 | Step: 1991 / 278000 | Reward: 0.000 / 4.000 | Loss: 0.001 | Epsilon: 0.109\n",
            "Episode: 175 | Step: 1861 / 279871 | Reward: 1.000 / 18.000 | Loss: 0.000 | Epsilon: 0.108\n",
            "Episode: 176 | Step: 129 / 280000 | Reward: 0.000 / -1.000 | Loss: 0.000 | Epsilon: 0.108\n",
            "Save Model ...\n",
            "Generate GIF ...\n",
            "Step: 1888 | Reward: 1.000 / 18.000\n",
            "Done !!\n",
            "Episode: 176 | Step: 130 / 280001 | Reward: 0.000 / -1.000 | Loss: 0.001 | Epsilon: 0.108\n",
            "Episode: 177 | Step: 1999 / 282000 | Reward: 0.000 / 9.000 | Loss: 0.001 | Epsilon: 0.107\n",
            "Episode: 178 | Step: 298 / 282300 | Reward: 0.000 / 2.000 | Loss: 0.001 | Epsilon: 0.1067"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(env_pong, agent, stack_frames, img_size, save_path\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m\"\u001b[39;49m\u001b[39m/content/\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msave\u001b[39;49m\u001b[39m\"\u001b[39;49m), max_steps\u001b[39m=\u001b[39;49m\u001b[39m400000\u001b[39;49m)\n",
            "Cell \u001b[1;32mIn[20], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(env, agent, stack_frames, img_size, save_path, max_steps)\u001b[0m\n\u001b[0;32m     24\u001b[0m agent\u001b[39m.\u001b[39mstore_transition(state, action, reward, state_next, done)\n\u001b[0;32m     25\u001b[0m \u001b[39mif\u001b[39;00m total_step \u001b[39m>\u001b[39m \u001b[39m4\u001b[39m\u001b[39m*\u001b[39magent\u001b[39m.\u001b[39mbatch_size:\n\u001b[1;32m---> 26\u001b[0m     loss \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mlearn()\n\u001b[0;32m     28\u001b[0m state \u001b[39m=\u001b[39m state_next\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     29\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "Cell \u001b[1;32mIn[13], line 68\u001b[0m, in \u001b[0;36mDeepQNetwork.learn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msmooth_l1_loss(q_curr_eval, q_curr_recur)\n\u001b[0;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 68\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     70\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearn_step_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[1;32md:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
            "File \u001b[1;32md:\\anaconda3\\envs\\RL-39\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(env_pong, agent, stack_frames, img_size, save_path=os.path.join(\"/content/\", \"save\"), max_steps=400000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SkxiarsXxrEn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 1888 | Reward: 1.000 / 18.000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained model\n",
        "agent.save_load_model(op=\"load\", path=os.path.join('/content', \"save\"), fname=\"qnet.pt\")\n",
        "img_buffer = play(env_pong, agent, stack_frames, img_size)\n",
        "save_gif(img_buffer, \"eval.gif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsyjXTMfqucX",
        "outputId": "c77df3dc-02b6-4190-c0e4-ab93df0357e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QNet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=512, out_features=6, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "cnn = QNet([4,84,84],6)\n",
        "print(cnn)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
